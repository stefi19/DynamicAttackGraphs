\documentclass[conference]{IEEEtran}

% ============================================================================
% PACKAGES
% ============================================================================
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usetikzlibrary{shapes,arrows,positioning,calc,patterns,decorations.pathmorphing}

% ============================================================================
% CODE LISTING STYLES
% ============================================================================
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{datalog}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue}\bfseries,
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single,
    morekeywords={execCode, netAccess, vulExists, hacl, attackerLocated, attackGoal, ownsMachine, goalReached}
}

\lstdefinestyle{rust}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue}\bfseries,
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single,
    language=C,
    morekeywords={let, fn, pub, struct, impl, use, mut, self, iterate, join, semijoin, antijoin, map, filter, concat, distinct, Collection, scope, enter}
}

% ============================================================================
% DOCUMENT
% ============================================================================
\begin{document}

\title{Incremental Attack Graph Computation\\Using Differential Dataflow}

\author{
\IEEEauthorblockN{Stefania-Cristina Mozacu}
\IEEEauthorblockA{
\textit{Department of Computing}\\
\textit{Imperial College London}\\
London, United Kingdom\\
stefania.mozacu@imperial.ac.uk}
\and
\IEEEauthorblockN{Emil C. Lupu}
\IEEEauthorblockA{
\textit{Department of Computing}\\
\textit{Imperial College London}\\
London, United Kingdom\\
e.c.lupu@imperial.ac.uk}
}

\maketitle

% ============================================================================
% ABSTRACT
% ============================================================================
\begin{abstract}
Attack graphs are fundamental tools for security analysis, modeling how an attacker can chain vulnerabilities to compromise network resources. However, traditional attack graph generation algorithms recompute the entire graph after each change, making them unsuitable for dynamic environments where vulnerabilities are constantly discovered and patched.

We present a novel approach to attack graph maintenance based on \textit{differential dataflow}, a computational model that automatically propagates changes through a dataflow graph. Our system translates Datalog-style security rules into differential dataflow operators, enabling \textit{incremental} updates: when a vulnerability is patched, only the affected attack paths are recomputed.

We evaluate our approach on synthetic network topologies ranging from 50 to 1000 nodes. For star topologies with localized changes, we achieve speedups of up to \textbf{25$\times$} compared to full recomputation. For chain topologies, we demonstrate that update time is proportional to the number of affected nodes, not the total network size. Our implementation is open-source and provides a foundation for real-time security monitoring in dynamic networks.
\end{abstract}

\begin{IEEEkeywords}
attack graphs, incremental computation, differential dataflow, network security, vulnerability analysis, Datalog
\end{IEEEkeywords}

% ============================================================================
% INTRODUCTION
% ============================================================================
\section{Introduction}

Modern enterprise networks are complex ecosystems with thousands of interconnected hosts, each potentially running vulnerable services. Security analysts use \textit{attack graphs} to understand how an attacker could exploit these vulnerabilities to move laterally through the network and reach critical assets~\cite{sheyner2002automated}. An attack graph is a directed graph where nodes represent security states (e.g., ``attacker has root access on host X'') and edges represent exploit actions that transition between states.

\subsection{Motivation}

Consider a typical enterprise network with the following characteristics:
\begin{itemize}
    \item \textbf{Scale}: Hundreds to thousands of hosts
    \item \textbf{Dynamics}: Vulnerabilities discovered daily (CVE database averages 50+ new entries per day~\cite{cvedetails})
    \item \textbf{Urgency}: Security teams need to assess patch priorities in real-time
\end{itemize}

Traditional attack graph tools like MulVAL~\cite{ou2006mulval} and NetSPA~\cite{ingols2006practical} regenerate the entire graph whenever the network state changes. For a network with $N$ hosts and $E$ network connections, this requires $O(E \times D)$ work, where $D$ is the diameter of the attack graph. When a single vulnerability is patched, the entire computation must be repeated---even if 99\% of the graph remains unchanged.

\subsection{Our Contribution}

We present an \textit{incremental} approach to attack graph maintenance using \textit{differential dataflow}~\cite{mcsherry2013differential}. Our key insight is that attack graph rules can be expressed as dataflow operators, and differential dataflow automatically tracks how changes propagate through these operators.

Our contributions are:

\begin{enumerate}
    \item \textbf{Translation methodology}: We show how to translate MulVAL-style Datalog rules into differential dataflow operators, including handling of recursive rules via fixed-point iteration and negation via antijoin.
    
    \item \textbf{Incremental maintenance}: Our system achieves update complexity of $O(\Delta E \times \Delta d)$, where $\Delta E$ is the number of affected edges and $\Delta d$ is the local iteration depth---compared to $O(E \times D)$ for full recomputation.
    
    \item \textbf{Empirical evaluation}: We demonstrate speedups of up to 25$\times$ for localized changes in star topologies and 2$\times$ average speedup for random changes in chain topologies.
    
    \item \textbf{Open-source implementation}: Our Rust implementation is publicly available, with Docker support for reproducibility.
\end{enumerate}

% ============================================================================
% BACKGROUND
% ============================================================================
\section{Background}

\subsection{Attack Graphs and MulVAL}

MulVAL (Multihost, Multistage Vulnerability Analysis)~\cite{ou2006mulval} is a widely-used framework that models attack graphs using Datalog, a declarative logic programming language. The key relations are:

\begin{itemize}
    \item \texttt{vulExists(Host, CVE, Service, Priv)}: Host has a vulnerability on a service that grants a privilege level
    \item \texttt{hacl(Src, Dst, Service)}: Network access control allows traffic from Src to Dst on Service
    \item \texttt{attackerLocated(Attacker, Host)}: Initial attacker position
    \item \texttt{execCode(Attacker, Host, Priv)}: Derived---attacker can execute code with privilege Priv on Host
\end{itemize}

The core inference rule is:

\begin{lstlisting}[style=datalog, caption={MulVAL lateral movement rule}]
execCode(Attacker, Host, Priv) :-
    execCode(Attacker, SrcHost, _),
    hacl(SrcHost, Host, Service),
    vulExists(Host, _, Service, Priv).
\end{lstlisting}

This rule states: if an attacker can execute code on \texttt{SrcHost}, and network access exists from \texttt{SrcHost} to \texttt{Host} on \texttt{Service}, and \texttt{Host} has a vulnerability on that service, then the attacker can execute code on \texttt{Host}.

\subsection{The Recomputation Problem}

MulVAL uses XSB Prolog to evaluate these rules. When any input fact changes (e.g., a vulnerability is patched), the entire Prolog query must be re-executed. This is because:

\begin{enumerate}
    \item Prolog evaluates rules top-down with backtracking
    \item There is no mechanism to identify which derived facts depend on the changed input
    \item The transitive closure (reachability) must be recomputed from scratch
\end{enumerate}

\subsection{Differential Dataflow}

Differential dataflow~\cite{mcsherry2013differential} is a computational model where:

\begin{enumerate}
    \item Data is represented as \textit{collections} of (record, time, multiplicity) tuples
    \item Operators (join, filter, map, etc.) transform collections
    \item Changes propagate \textit{incrementally}---when an input changes, only the affected outputs are updated
    \item Fixed-point iteration is supported via the \texttt{iterate} operator
\end{enumerate}

The key abstraction is the \textit{difference}: when a record is added, it has multiplicity $+1$; when removed, $-1$. Operators propagate these differences through the dataflow graph. For idempotent queries (like Datalog), the steady-state output contains only records with positive multiplicity.

\begin{figure}[t]
\centering
\begin{tikzpicture}[
    node distance=0.8cm and 1.2cm,
    box/.style={rectangle, draw, rounded corners, minimum width=1.8cm, minimum height=0.6cm, align=center, fill=blue!10},
    input/.style={rectangle, draw, rounded corners, minimum width=1.8cm, minimum height=0.6cm, align=center, fill=green!20},
    output/.style={rectangle, draw, rounded corners, minimum width=1.8cm, minimum height=0.6cm, align=center, fill=red!20},
    arrow/.style={->, thick, >=stealth}
]
    % Inputs
    \node[input] (vuln) {Vulnerabilities};
    \node[input, right=of vuln] (net) {Network\\Access};
    \node[input, right=of net] (att) {Attacker\\Position};
    
    % Processing
    \node[box, below=1cm of net] (join1) {Join};
    \node[box, below=of join1] (filter) {Semijoin};
    \node[box, below=of filter] (iterate) {Iterate\\(fixed-point)};
    
    % Output
    \node[output, below=of iterate] (exec) {execCode};
    
    % Arrows
    \draw[arrow] (vuln) -- (join1);
    \draw[arrow] (net) -- (join1);
    \draw[arrow] (att) -- (filter);
    \draw[arrow] (join1) -- (filter);
    \draw[arrow] (filter) -- (iterate);
    \draw[arrow] (iterate) -- (exec);
    
    % Feedback loop
    \draw[arrow] (iterate.east) -- ++(0.5,0) |- (filter.east);
    
\end{tikzpicture}
\caption{Differential dataflow graph for attack graph computation. Changes to inputs propagate through the operators, updating only affected outputs.}
\label{fig:dataflow}
\end{figure}

% ============================================================================
% SYSTEM DESIGN
% ============================================================================
\section{System Design}

\subsection{Architecture Overview}

Our system consists of three components:

\begin{enumerate}
    \item \textbf{Input handles}: Mutable collections for vulnerabilities, network topology, firewall rules, and attacker state
    \item \textbf{Dataflow graph}: Compiled Datalog rules as differential operators (Figure~\ref{fig:dataflow})
    \item \textbf{Output probes}: Allow querying the current attack graph state
\end{enumerate}

\subsection{Rule Translation}

We translate each Datalog rule into a composition of differential dataflow operators:

\begin{itemize}
    \item \textbf{Conjunction} ($\land$) $\rightarrow$ \texttt{join}
    \item \textbf{Projection} $\rightarrow$ \texttt{map}
    \item \textbf{Selection} $\rightarrow$ \texttt{filter}
    \item \textbf{Recursion} $\rightarrow$ \texttt{iterate}
    \item \textbf{Negation} $\rightarrow$ \texttt{antijoin}
    \item \textbf{Deduplication} $\rightarrow$ \texttt{distinct}
\end{itemize}

\subsubsection{Handling Recursion}

The \texttt{execCode} relation is recursive: an attacker can reach host B from host A, then host C from host B, and so on. We implement this using differential dataflow's \texttt{iterate} operator:

\begin{lstlisting}[style=rust, caption={Recursive reachability in differential dataflow}]
let reachable = attacker_positions.iterate(|inner| {
    let network = network_access.enter(&inner.scope());
    let vulns = vulnerabilities.enter(&inner.scope());
    
    inner
        .map(|(att, host)| (host, att))
        .join(&network)  // (host, (att, (dst, svc)))
        .map(|(_, (att, (dst, svc)))| ((dst, svc), att))
        .semijoin(&vulns)  // keep if vulnerable
        .map(|((dst, _), att)| (att, dst))
        .concat(inner)
        .distinct()
});
\end{lstlisting}

The \texttt{iterate} operator continues until no new records are produced---the fixed point.

\subsubsection{Handling Negation with Antijoin}

Firewall rules introduce negation: traffic is allowed unless explicitly blocked. We implement this using the \textit{antijoin} operator:

\begin{equation}
\text{effectiveAccess} = \text{netAccess} \bowtie_{\bar{\exists}} \text{firewallBlock}
\end{equation}

The antijoin $A \bowtie_{\bar{\exists}} B$ returns tuples from $A$ that have no matching tuple in $B$. When a firewall rule is added, the antijoin removes the corresponding access tuples; when removed, it restores them.

\subsection{Incremental Updates}

When an input fact changes (e.g., a vulnerability is removed), the system:

\begin{enumerate}
    \item Inserts a difference tuple with multiplicity $-1$
    \item Propagates this difference through all dependent operators
    \item For joins, produces negative outputs for matching tuples
    \item For iterations, continues until the fixed point stabilizes
    \item Outputs only the changes (not the entire new state)
\end{enumerate}

The key insight is that unaffected parts of the graph produce no differences---they incur zero computational cost.

% ============================================================================
% EVALUATION
% ============================================================================
\section{Evaluation}

We evaluate three research questions:

\begin{enumerate}
    \item[\textbf{RQ1}] How does incremental update time compare to full recomputation?
    \item[\textbf{RQ2}] How does speedup scale with network size?
    \item[\textbf{RQ3}] How does the position of a change affect update time?
\end{enumerate}

\subsection{Experimental Setup}

\begin{itemize}
    \item \textbf{Hardware}: Apple M-series processor, 16GB RAM
    \item \textbf{Software}: Rust 1.75, differential-dataflow 0.12
    \item \textbf{Execution}: Single-threaded, release mode with optimizations
    \item \textbf{Metric}: Wall-clock time (median of 5 runs)
\end{itemize}

\subsection{Network Topologies}

We evaluate two synthetic topologies that represent extremes of attack graph structure:

\subsubsection{Star Topology}
A central hub connected to $N$ leaf nodes. The attacker starts at the hub and can reach any leaf in one hop. This represents a data center with a management server connected to many hosts.

\begin{itemize}
    \item \textbf{Iteration depth}: $O(1)$---converges in constant iterations
    \item \textbf{Change tested}: Patch vulnerability on one leaf
    \item \textbf{Expected behavior}: Only one attack path affected
\end{itemize}

\subsubsection{Chain Topology}
A linear chain: node$_0 \rightarrow$ node$_1 \rightarrow \cdots \rightarrow$ node$_{N-1}$. The attacker starts at node$_0$ and the goal is node$_{N-1}$. This represents a worst-case scenario for incremental computation.

\begin{itemize}
    \item \textbf{Iteration depth}: $O(N)$---requires $N$ iterations to converge
    \item \textbf{Change tested}: Patch vulnerability at position $k$
    \item \textbf{Expected behavior}: All nodes $k+1$ to $N-1$ lose their attack paths
\end{itemize}

\subsection{RQ1: Incremental vs. Full Recomputation}

\begin{table}[t]
\centering
\caption{Star Network Benchmark Results}
\label{tab:star}
\begin{tabular}{@{}rrrr@{}}
\toprule
\textbf{Nodes} & \textbf{Initial (ms)} & \textbf{Incremental ($\mu$s)} & \textbf{Speedup} \\
\midrule
51    & 1.58 & 501  & 3.2$\times$ \\
101   & 1.96 & 413  & 4.7$\times$ \\
201   & 1.97 & 349  & 5.6$\times$ \\
501   & 3.48 & 282  & 12.4$\times$ \\
1001  & 4.11 & 161  & \textbf{25.6$\times$} \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:star} shows results for the star topology. Key observations:

\begin{itemize}
    \item Initial computation scales linearly with network size ($\approx$4ms for 1000 nodes)
    \item Incremental update time is \textit{nearly constant} ($\approx$160$\mu$s regardless of size)
    \item Speedup increases with network size, reaching \textbf{25$\times$} at 1000 nodes
\end{itemize}

This confirms that for localized changes, incremental computation achieves $O(1)$ update complexity.

\subsection{RQ2: Scalability}

\begin{figure}[t]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=\columnwidth,
    height=5cm,
    xlabel={Number of nodes},
    ylabel={Time (ms)},
    legend pos=north west,
    grid=major,
    xmin=0, xmax=1100,
    ymin=0, ymax=5,
]
\addplot[color=blue, mark=square*, thick] coordinates {
    (51, 1.58)
    (101, 1.96)
    (201, 1.97)
    (501, 3.48)
    (1001, 4.11)
};
\addlegendentry{Initial computation}

\addplot[color=red, mark=*, thick] coordinates {
    (51, 0.501)
    (101, 0.413)
    (201, 0.349)
    (501, 0.282)
    (1001, 0.161)
};
\addlegendentry{Incremental update}
\end{axis}
\end{tikzpicture}
\caption{Star topology: Initial computation scales linearly while incremental updates remain constant.}
\label{fig:scalability}
\end{figure}

Figure~\ref{fig:scalability} visualizes the scalability results. The gap between initial and incremental computation widens as network size increases, demonstrating the value of incremental maintenance for large networks.

\subsection{RQ3: Position-Dependent Updates}

To understand how the \textit{location} of a change affects update time, we perform a ``random cut'' experiment on chain topologies:

\begin{enumerate}
    \item Generate a chain of $N$ nodes
    \item Randomly select position $k \in [0, N-1]$
    \item Remove the vulnerability at node$_k$
    \item Measure update time
    \item Restore the vulnerability and repeat
\end{enumerate}

We perform 100 iterations per chain size.

\begin{table}[t]
\centering
\caption{Random Cut Benchmark (Chain Topology, 100 iterations)}
\label{tab:random}
\begin{tabular}{@{}rrrrrr@{}}
\toprule
\textbf{Nodes} & \textbf{Avg ($\mu$s)} & \textbf{Min ($\mu$s)} & \textbf{Max ($\mu$s)} & \textbf{Speedup} \\
\midrule
50   & 905   & 46   & 1877  & 2.3$\times$ \\
100  & 1707  & 110  & 3799  & 2.1$\times$ \\
200  & 3468  & 182  & 7062  & 2.0$\times$ \\
500  & 9289  & 65   & 19171 & 1.9$\times$ \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:random} reveals:

\begin{itemize}
    \item \textbf{Minimum time} ($\approx$50--180$\mu$s): Cutting near the \textit{end} of the chain invalidates only 1--2 downstream nodes
    \item \textbf{Maximum time} ($\approx$1.8--19ms): Cutting near the \textit{start} invalidates all $N$ downstream nodes
    \item \textbf{Average speedup} $\approx 2\times$: Cutting at random position $k$ invalidates $(N-k)$ nodes on average, i.e., $N/2$
\end{itemize}

This confirms that update time is $O(\text{affected nodes})$, not $O(\text{total nodes})$.

\subsection{Complexity Analysis}

\begin{table}[t]
\centering
\caption{Complexity Comparison}
\label{tab:complexity}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Operation} & \textbf{Full Recomputation} & \textbf{Incremental} \\
\midrule
Initial build & $O(E \times D)$ & $O(E \times D)$ \\
Single change & $O(E \times D)$ & $O(\Delta E \times \Delta d)$ \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:complexity} summarizes the complexity:
\begin{itemize}
    \item $E$ = number of network edges
    \item $D$ = diameter of attack graph (longest path)
    \item $\Delta E$ = edges affected by the change
    \item $\Delta d$ = local iteration depth of affected region
\end{itemize}

For localized changes (e.g., patching one vulnerability), $\Delta E \ll E$ and $\Delta d \ll D$, yielding significant speedups.

% ============================================================================
% DISCUSSION
% ============================================================================
\section{Discussion}

\subsection{When Incremental Computation Helps}

Our approach is most beneficial when:

\begin{enumerate}
    \item \textbf{Changes are localized}: Patching a single vulnerability affects few attack paths
    \item \textbf{Topology is shallow}: Star, tree, or mesh networks with low diameter
    \item \textbf{Updates are frequent}: Real-time monitoring scenarios where latency matters
\end{enumerate}

\subsection{Limitations}

Our approach has comparable performance to full recomputation when:

\begin{enumerate}
    \item \textbf{Changes are global}: Modifying the attacker's starting position affects all reachable nodes
    \item \textbf{Topology is deep}: Long chains where changes near the start invalidate everything downstream
    \item \textbf{Changes are batched}: Many simultaneous changes may approach full recomputation cost
\end{enumerate}

However, even in worst-case scenarios, incremental computation is \textit{never slower} than full recomputation.

\subsection{Practical Considerations}

Our implementation uses Rust and the \texttt{timely} dataflow framework. Key engineering decisions:

\begin{itemize}
    \item \textbf{Single-threaded execution}: We use \texttt{execute\_directly} for benchmarking consistency. Production deployments can scale across cores.
    \item \textbf{String-based identifiers}: Host names are strings for clarity. Production systems could use integer IDs for performance.
    \item \textbf{Memory overhead}: Differential dataflow maintains internal state proportional to the collection size. For very large networks, this may require attention.
\end{itemize}

% ============================================================================
% RELATED WORK
% ============================================================================
\section{Related Work}

\subsection{Attack Graph Generation}

Sheyner et al.~\cite{sheyner2002automated} introduced model-checking approaches to attack graph generation. Ammann et al.~\cite{ammann2002scalable} proposed scalable algorithms based on graph reachability. MulVAL~\cite{ou2006mulval} pioneered the use of Datalog for declarative attack modeling, which we build upon.

NetSPA~\cite{ingols2006practical} and TVA~\cite{jajodia2005topological} provide efficient attack graph visualization but do not support incremental updates.

\subsection{Incremental Datalog}

Incremental view maintenance for Datalog has been studied extensively~\cite{gupta1993maintaining}. The DRed algorithm~\cite{staudt1995incremental} handles recursive rules but requires explicit deletion tracking. Differential dataflow provides a general framework that subsumes these approaches.

\subsection{Dataflow Systems}

Naiad~\cite{murray2013naiad} introduced timely dataflow for iterative computation. Differential dataflow~\cite{mcsherry2013differential} extended this with change tracking. Our work is the first application of differential dataflow to security analysis.

% ============================================================================
% CONCLUSION
% ============================================================================
\section{Conclusion}

We presented an incremental approach to attack graph maintenance using differential dataflow. By translating Datalog-style security rules into dataflow operators, we enable automatic change propagation: when a vulnerability is patched, only the affected attack paths are recomputed.

Our evaluation demonstrates:

\begin{enumerate}
    \item \textbf{Significant speedups}: Up to 25$\times$ for localized changes in star topologies
    \item \textbf{Proportional updates}: Update time scales with affected nodes, not total network size
    \item \textbf{No regression}: Worst-case performance matches full recomputation
\end{enumerate}

This approach enables real-time security monitoring for dynamic networks, where sub-millisecond updates allow continuous assessment of security posture.

\subsection{Future Work}

\begin{itemize}
    \item \textbf{Parallel execution}: Leverage multiple cores via timely dataflow's distributed execution
    \item \textbf{Real-world integration}: Connect to vulnerability scanners (Nessus, OpenVAS) and SIEM systems
    \item \textbf{Probabilistic extensions}: Compute attack probabilities incrementally
    \item \textbf{Visualization}: Interactive attack graph exploration with real-time updates
\end{itemize}

\subsection{Reproducibility}

Our implementation is open-source and available at:
\begin{center}
\url{https://github.com/stefi19/DynamicAttackGraphs}
\end{center}

A Docker container is provided for reproducibility:
\begin{lstlisting}[language=bash, frame=none, numbers=none]
docker build -t attack-graph .
docker run --rm attack-graph
\end{lstlisting}

% ============================================================================
% ACKNOWLEDGMENTS
% ============================================================================
\section*{Acknowledgments}

We thank the differential-dataflow community for their excellent documentation and the reviewers for their constructive feedback.

% ============================================================================
% REFERENCES
% ============================================================================
\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
